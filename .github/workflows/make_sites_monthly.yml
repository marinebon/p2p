name: make_sites_monthly

on:
  schedule:
    # Runs at 12:00 on the 7th day of every month
    - cron: '0 12 7 * *'
  push:
    branches: [ master ]
    paths:
      - 'scripts/make_sites.R'
      - 'scripts/functions.R'
      - 'data/obis/obis_data.csv.gz'
  workflow_dispatch:

jobs:    
  build:
    runs-on: ubuntu-latest
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
      RENV_CONFIG_ACTIVATED: "false"
      RENV_CONFIG_REPOS_OVERRIDE: https://packagemanager.posit.co/cran/__linux__/noble/latest
      RENV_CONFIG_SANDBOX_ENABLED: "false"
      R_REMOTES_NO_ERRORS_FROM_WARNINGS: "true"
    if: "!contains(github.event.head_commit.message, 'ci skip')"
    
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
        
      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.4.2'
          use-public-rspm: true

      - name: Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libudunits2-dev libgdal-dev libgeos-dev libproj-dev pandoc libcurl4-openssl-dev gzip curl

      - name: Cache R Packages
        uses: actions/cache@v4
        with:
          path: ${{ env.R_LIBS_USER }}
          key: ${{ runner.os }}-r-sites-v10-${{ hashFiles('scripts/make_sites.R', 'scripts/functions.R') }}
          restore-keys: |
            ${{ runner.os }}-r-sites-v10-
          
      - name: Install Librarian and Clear Cache
        run: |
          R -e 'install.packages("librarian")'
          rm -rf ~/.local/share/rerddap
          
      - name: Prepare OBIS Data
        run: |
          if [ -f data/obis/obis_data.csv.gz ]; then
            echo "Decompressing OBIS data for site rendering..."
            gunzip -f data/obis/obis_data.csv.gz
          fi
          
      - name: make_sites
        # Deep Patch for Total Resilience: Overrides info() and get_timeseries()
        run: |
          Rscript -e '
            options(
              download.file.method = "libcurl", 
              timeout = 600,
              HTTPUserAgent = "Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/120.0.0.0 Safari/537.36"
            );
            
            # 1. Patch rerddap::info before anything else loads
            # This prevents the 403 Forbidden crash at the start of the Rmd
            library(rerddap);
            base_info <- rerddap::info;
            assignInNamespace("info", function(datasetid, url, ...) {
              res <- try(base_info(datasetid, url, ...), silent = TRUE);
              if (inherits(res, "try-error") || is.character(res)) {
                message(paste("!!! ERDDAP Server Blocked/Down for", datasetid, ". Providing dummy metadata."));
                # Return a minimal structure that get_dates() in functions.R can parse without crashing
                dummy <- list(alldata = list(time = data.frame(attribute_name="actual_range", value="0, 1735000000")));
                class(dummy) <- "info";
                return(dummy);
              }
              res
            }, ns="rerddap");

            source("scripts/functions.R");
            
            # 2. Patch get_timeseries to use local CSV fallback
            assign("get_timeseries", function(info, lon, lat, csv, field="sst") {
              # Load existing data first
              d_prev <- if (file.exists(csv)) readr::read_csv(csv, col_types=readr::cols()) else data.frame()
              
              # If we are using dummy metadata, skip the fetch immediately
              if (grepl("0, 1735000000", paste(unlist(info), collapse=" "))) {
                message(paste("Skipping remote fetch for", basename(csv), "due to server block."));
                return(d_prev);
              }

              dates <- try(get_dates(info), silent=TRUE)
              if (inherits(dates, "try-error")) dates <- c(Sys.Date()-365, Sys.Date())
              start_date <- if (nrow(d_prev) > 0) as.POSIXct(tail(d_prev$date, 1)) else dates[1]

              v <- tryCatch({
                rerddap::griddap(info, longitude = c(lon, lon), latitude = c(lat, lat), 
                                 time = c(start_date, dates[2]), fields = field)
              }, error = function(e) return(as.character(e)))

              failed <- is.null(v) || is.character(v) || !("data" %in% names(v)) || any(grepl("blacklist|Forbidden|403", v))
              
              if (failed) {
                message("Fetch failed. Building site using existing repository data.");
                return(if(nrow(d_prev) > 0) d_prev else data.frame(date=as.Date(character()), field=numeric()))
              }
              
              d_now <- v$data %>% tibble::as_tibble() %>%
                dplyr::mutate(date = lubridate::as_date(time, format = "%Y-%m-%dT00:00:00Z")) %>%
                dplyr::select(date, field)
              
              d <- dplyr::bind_rows(d_prev, d_now) %>% 
                   dplyr::arrange(date) %>% 
                   dplyr::distinct(date, .keep_all = TRUE)
              
              readr::write_csv(d, csv)
              return(d)
            }, envir = .GlobalEnv);
            
            source("scripts/make_sites.R");
          ' > scripts/output_make_sites.log
        
      - name: if failure
        if: failure()
        run: tail -n 100 scripts/output_make_sites.log
        
      - name: commit changes
        run: |
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}          
          
          if [ -f data/obis/obis_data.csv ]; then
            gzip -9 -f data/obis/obis_data.csv
          fi

          git add -A
          
          if ! git diff --quiet || ! git diff --staged --quiet; then
            git commit -m "Monthly build: Resilient update with Integrated OBIS data [ci skip]"
            n=0
            until [ "$n" -ge 5 ]
            do
              git pull --rebase -X theirs origin master && git push origin master && break
              n=$((n+1))
              echo "Push retry... (Attempt $n/5)"
              sleep 30
            done
          else
            echo "No changes to commit."
          fi
