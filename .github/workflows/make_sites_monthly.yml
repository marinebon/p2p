name: make_sites_monthly

on:
  schedule:
    # Runs at 12:00 on the 7th day of every month
    - cron: '0 12 7 * *'
  push:
    branches: [ master ]
    paths:
      - 'scripts/make_sites.R'
      - 'scripts/functions.R'
      - 'data/obis/obis_data.csv.gz'
  workflow_dispatch:

jobs:    
  build:
    runs-on: ubuntu-latest
    env:
      GITHUB_PAT: ${{ secrets.GITHUB_TOKEN }}
      RENV_CONFIG_ACTIVATED: "false"
      RENV_CONFIG_REPOS_OVERRIDE: https://packagemanager.posit.co/cran/__linux__/noble/latest
      RENV_CONFIG_SANDBOX_ENABLED: "false"
      R_REMOTES_NO_ERRORS_FROM_WARNINGS: "true"
    if: "!contains(github.event.head_commit.message, 'ci skip')"
    
    steps:
      - name: Checkout repo
        uses: actions/checkout@v4
        with:
          fetch-depth: 0
        
      - name: Setup R
        uses: r-lib/actions/setup-r@v2
        with:
          r-version: '4.4.2'
          use-public-rspm: true

      - name: Install System Dependencies
        run: |
          sudo apt-get update
          sudo apt-get install -y libudunits2-dev libgdal-dev libgeos-dev libproj-dev pandoc libcurl4-openssl-dev gzip curl

      - name: Cache R Packages
        uses: actions/cache@v4
        with:
          path: ${{ env.R_LIBS_USER }}
          key: ${{ runner.os }}-r-sites-v7-${{ hashFiles('scripts/make_sites.R', 'scripts/functions.R') }}
          restore-keys: |
            ${{ runner.os }}-r-sites-v7-
          
      - name: Install Librarian and Clear Cache
        run: |
          R -e 'install.packages("librarian")'
          rm -rf ~/.local/share/rerddap
          
      - name: Prepare OBIS Data
        run: |
          if [ -f data/obis/obis_data.csv.gz ]; then
            echo "Decompressing OBIS data..."
            gunzip -f data/obis/obis_data.csv.gz
          fi
          
      - name: make_sites
        # We use a Deep Patch to overwrite get_timeseries in memory
        run: |
          Rscript -e '
            options(download.file.method = "libcurl", timeout = 600);
            source("scripts/functions.R");
            
            # The "Safe-Fail" version of your function
            patched_get_timeseries <- function(info, lon, lat, csv, field="sst") {
              dates <- try(get_dates(info), silent=TRUE)
              if (inherits(dates, "try-error")) dates <- c(Sys.Date()-365, Sys.Date())

              if (file.exists(csv)) {
                d_prev <- readr::read_csv(csv, col_types=readr::cols())
                start_date <- as.POSIXct(tail(d_prev$date, 1))
              } else {
                start_date <- dates[1]
                d_prev <- data.frame()
              }

              message(paste("Fetching data for", csv, "..."))
              v <- tryCatch({
                rerddap::griddap(info, longitude = c(lon, lon), latitude = c(lat, lat), 
                                 time = c(start_date, dates[2]), fields = field)
              }, error = function(e) return(NULL))

              # CHECK: Handle the atomic vector/null crash before accessing $data
              if (is.null(v) || is.character(v) || !("data" %in% names(v))) {
                message("Server error or timeout. Skipping fetch for this site.");
                return(if(nrow(d_prev) > 0) d_prev else data.frame(date=as.Date(character()), field=numeric()))
              }
              
              d_now <- v$data %>% tibble::as_tibble() %>%
                dplyr::mutate(date = lubridate::as_date(time, format = "%Y-%m-%dT00:00:00Z")) %>%
                dplyr::select(date, field)
              
              d <- dplyr::bind_rows(d_prev, d_now) %>% 
                   dplyr::arrange(date) %>% 
                   dplyr::distinct(date, .keep_all = TRUE)
              
              readr::write_csv(d, csv)
              return(d)
            }
            
            # DEEP PATCH: Force the override into the Global Environment
            assign("get_timeseries", patched_get_timeseries, envir = .GlobalEnv);
            
            source("scripts/make_sites.R");
          ' > scripts/output_make_sites.log
        
      - name: if failure
        if: failure()
        run: |
          echo "--- ERROR CONTEXT ---"
          tail -n 100 scripts/output_make_sites.log
        
      - name: commit changes
        run: |
          git config --local user.email "41898282+github-actions[bot]@users.noreply.github.com"
          git config --local user.name "github-actions[bot]"
          git remote set-url origin https://x-access-token:${{ secrets.GITHUB_TOKEN }}@github.com/${{ github.repository }}          
          
          if [ -f data/obis/obis_data.csv ]; then
            gzip -9 -f data/obis/obis_data.csv
          fi

          git add -A
          
          if ! git diff --quiet || ! git diff --staged --quiet; then
            git commit -m "Monthly sites update (Resilient Build) [ci skip]"
            n=0
            until [ "$n" -ge 5 ]
            do
              git pull --rebase -X theirs origin master && git push origin master && break
              n=$((n+1))
              echo "Race condition detected. Retrying push... (Attempt $n/5)"
              sleep 30
            done
          else
            echo "No changes to commit."
          fi
